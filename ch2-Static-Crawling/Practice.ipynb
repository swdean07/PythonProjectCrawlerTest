{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T07:43:54.671913Z",
     "start_time": "2025-02-20T07:43:54.668220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# #ë¹…ë°ì´í„°_ìˆ˜ì§‘_ì €ì¥ #ë¯¸ë‹ˆì‹¤ìŠµ,\n",
    "# ì •ì  í¬ë¡¤ë§,\n",
    "# ê´€ì‹¬ ìˆëŠ” ì‚¬ì´íŠ¸ì—ê°€ì„œ,\n",
    "#\n",
    "# 1) í•´ë‹¹ ì‚¬ì´íŠ¸ ì£¼ì†Œ/robots.txt\n",
    "# í™•ì¸í•´ì„œ, í—ˆìš© ê°€ëŠ¥í•œì§€ ì—¬ë¶€ íŒë‹¨.\n",
    "#\n",
    "# 2) í•´ë‹¹ ì‚¬ì´íŠ¸ êµ¬ì¡°,\n",
    "# ë¦¬ì•¡íŠ¸ ì²˜ëŸ¼, íŠ¹ì •ì˜ í•¨ìˆ˜ë“±ì„ í˜¸ì¶œí•´ì„œ,\n",
    "# ë°ì´í„°ë¥¼ ë°›ì•„ì„œ ì¶œë ¥ì´ë©´,\n",
    "# ìˆ˜ì§‘ í•  ë°ì´í„°ê°€, í™”ë©´ì—ì„œ, í˜ì´ì§€ ì†ŒìŠ¤ ë³´ê¸°ë¥¼ í–ˆì„ ê²½ìš°,\n",
    "# í•´ë‹¹ ë°ì´í„°ê°€ ì •ì ìœ¼ë¡œ ì¡´ì¬í•´ì•¼ ìˆ˜ì§‘ ê°€ëŠ¥.\n",
    "#\n",
    "# 3) 3ê°€ì§€ ì´ìƒì˜ ë°ì´í„°ë¥¼ ìˆ˜ì§‘\n",
    "# -(ë©”ëª¨ë¦¬)\n",
    "# - json\n",
    "# - csv\n",
    "# - ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥."
   ],
   "id": "d812e05df6f49f2b",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T08:27:35.860642Z",
     "start_time": "2025-02-20T08:27:35.115993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "import bs4\n",
    "import urllib.request\n",
    "import csv\n",
    "import json\n",
    "import pymysql\n",
    "wikipediaUrl = \"https://en.wikipedia.org/wiki/78th_British_Academy_Film_Awards\"\n",
    "req = urllib.request.Request(wikipediaUrl, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "htmlObject = urllib.request.urlopen(wikipediaUrl)\n",
    "webPage = htmlObject.read()\n",
    "bsObject = bs4.BeautifulSoup(webPage, 'html.parser')\n",
    "\n",
    "#ì „ì²´ í˜ì´ì§€ í…ìŠ¤íŠ¸ ì €ì¥\n",
    "full_text = bsObject.get_text(separator=\"\\n\",strip=True)\n",
    "\n",
    "#ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥\n",
    "text_filename = \"wikipedia_full_text.txt\"\n",
    "with open(text_filename, \"w\", encoding=\"utf-8\") as text_file:\n",
    "    text_file.write(full_text)\n",
    "\n",
    "print(f\"ğŸ“„ ì „ì²´ í˜ì´ì§€ í…ìŠ¤íŠ¸ê°€ {text_filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "#í˜ì´ì§€ ì œëª© ì¶”ì¶œ\n",
    "page_title = bsObject.find(\"h1\", {\"id\": \"firstHeading\"}).text.strip()\n",
    "print(\"page_title:\", page_title)\n",
    "\n",
    "#ìœ„í‚¤í…Œì´ë¸” ë°ì´í„° ì¶”ì¶œ\n",
    "wikitable_list = bsObject.find_all(\"table\", {\"class\": \"wikitable\"})\n",
    "print(f\"Found {len(wikitable_list)} wikitable(s)\")"
   ],
   "id": "56e1f768c067861c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ ì „ì²´ í˜ì´ì§€ í…ìŠ¤íŠ¸ê°€ wikipedia_full_text.txtì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "page_title: 78th British Academy Film Awards\n",
      "Found 3 wikitable(s)\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T08:27:41.072257Z",
     "start_time": "2025-02-20T08:27:41.059128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#ê²°ê³¼ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬(JSON ì €ì¥ìš©)\n",
    "tables_data ={}\n",
    "\n",
    "#CSV, JSON, DBì— ì €ì¥ì„ ìœ„í•œ ê° í…Œì´ë¸” ì²˜ë¦¬\n",
    "for table_index, table in enumerate(wikitable_list, start=1):\n",
    "    table_data = []\n",
    "    rows = table.find_all(\"tr\")\n",
    "\n",
    "    for row in rows:\n",
    "        cells = row.find_all([\"th\", \"td\"])\n",
    "        row_data = [cell.get_text(strip=True) for cell in cells]\n",
    "        table_data.append(row_data)\n",
    "\n",
    "    #CSV íŒŒì¼ë¡œ ì €ì¥(í…Œì´ë¸” ë²ˆí˜¸ë³„ íŒŒì¼ ìƒì„±)\n",
    "    csv_filename = f\"wikitable_{table_index}.csv\"\n",
    "    with open(csv_filename, \"w\", encoding=\"utf-8\") as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerows(table_data)\n",
    "    print(f\"ğŸ“ Table {table_index} ë°ì´í„°ê°€ {csv_filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    #JSON ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬ì— ì¶”ê°€\n",
    "    tables_data[f\"table_{table_index}\"] = table_data\n",
    "\n",
    "#JSON íŒŒì¼ì— ì €ì¥(ëª¨ë“  í…Œì´ë¸” ë°ì´í„°)\n",
    "json_filename = \"wikitable_data.json\"\n",
    "with open(json_filename, \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(tables_data, json_file, ensure_ascii=False, indent=4)\n",
    "print(f\"ğŸ“‚ ëª¨ë“  í…Œì´ë¸” ë°ì´í„°ê°€ {json_filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ],
   "id": "dc08bd32d4dfb56",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Table 1 ë°ì´í„°ê°€ wikitable_1.csvì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ğŸ“ Table 2 ë°ì´í„°ê°€ wikitable_2.csvì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ğŸ“ Table 3 ë°ì´í„°ê°€ wikitable_3.csvì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "ğŸ“‚ ëª¨ë“  í…Œì´ë¸” ë°ì´í„°ê°€ wikitable_data.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T08:27:44.339551Z",
     "start_time": "2025-02-20T08:27:44.324032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# db ì—°ê²° ì‘ì—…,\n",
    "db = pymysql.connect(host=\"localhost\", user=\"webuser\", passwd=\"webuser\", db=\"webdb\",charset=\"utf8mb4\")\n",
    "cursor = db.cursor()\n",
    "\n",
    "def is_safe_name(name):\n",
    "    return bool(re.match(r'^[A-Za-z0-9_]+$', name))\n",
    "\n",
    "try:\n",
    "    # í…Œì´ë¸” ë³„ ë°ì´í„° ì €ì¥\n",
    "    for table_name, table_data in tables_data.items():\n",
    "        if not table_data:\n",
    "            continue\n",
    "\n",
    "        if not is_safe_name(table_name):\n",
    "            print(f\"í…Œì´ë¸” ì´ë¦„ '{table_name}'ì´ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "            continue\n",
    "\n",
    "        header = table_data[0]\n",
    "        num_columns = len(header)\n",
    "\n",
    "        for column in header:\n",
    "            if not is_safe_name(column):\n",
    "                print(f\"ì»¬ëŸ¼ ì´ë¦„ '{column}'ì´ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "                continue\n",
    "\n",
    "    # 7. ë³€ê²½ ì‚¬í•­ ì €ì¥ (commit)\n",
    "    db.commit()\n",
    "    print(\"âœ… MySQL ë°ì´í„°ë² ì´ìŠ¤ì— ë°ì´í„° ì €ì¥ ì™„ë£Œ!\")\n",
    "\n",
    "except Exception as e:\n",
    "    db.rollback()  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¡¤ë°±\n",
    "    print(f\"âŒ DB ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "finally:\n",
    "    cursor.close()\n",
    "    db.close()  # ì—°ê²° ì¢…ë£Œ\n"
   ],
   "id": "e88f17610e3a7bb4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì»¬ëŸ¼ ì´ë¦„ 'Best FilmConclaveâ€“Tessa Ross, Juliette Howell, and Michael A. JackmanAnoraâ€“ Alex Coco,Samantha Quan, andSean BakerThe Brutalistâ€“ Nick Gordon, Brian Young, Andrew Morrison, D.J. Gugenheim, andBrady CorbetA Complete Unknownâ€“ Alex Heineman,Fred Berger, andJames MangoldEmilia PÃ©rezâ€“ Pascal Caucheteux andJacques Audiard'ì´ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
      "ì»¬ëŸ¼ ì´ë¦„ 'Best DirectorBrady Corbetâ€“The BrutalistJacques Audiardâ€“Emilia PÃ©rezSean Bakerâ€“AnoraEdward Bergerâ€“ConclaveCoralie Fargeatâ€“The SubstanceDenis Villeneuveâ€“Dune: Part Two'ì´ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
      "âœ… MySQL ë°ì´í„°ë² ì´ìŠ¤ì— ë°ì´í„° ì €ì¥ ì™„ë£Œ!\n"
     ]
    }
   ],
   "execution_count": 77
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
